非监督学习是指在没有类别信息情况下，通过对所研究对象的大量样本的数据分析实现对样本分类的一种数据处理方法。

## 简述
由于在很多实际应用中，缺少所研究对象类别形成过程的知识，或者为了判断各个样本(模式)所属的类别需要很大的工作量(例如卫星遥感照片上各像元所对应的地面情况)，因此往往只能用无类别标答的样本集进形学习。通过无监督式学习，把样本集划分为若干个子集(类别)，从而直接解决看样本的分类问题，或者把它作为训练样本集，再用监督学习方法进行分类器设计。

## 思路
在非监督学习中，数据并不会被特别标识，学习模型是为了推断出数据的一些内在结构。非监督学习一般有两种思路：
1)第一种思路是在指导Agent时不为其指定明确的分类，而是在成功时采用某种形式的激励制度。需要注意的是，这类训练通常会被置于决策问题的框架里，因为它的目标不是产生一个分类系统，而是做出最大回报的决定，这类学习往往被称为强化学习。
2)第二种思路称为聚合(Clustering)，这类学习类型的目标不是让效用函数最大化，而是找到训练数据中的近似点，本节将重点介绍此类非监督学习思路。
第二种思路的非监督学习常见的应用场景包括关联规则的学习及聚类等。常见算法包括Apriori、K-Means、EM等。

## 方法
无监督学习主要有以下两大类方法：
(1)基于概率密度函数估计的直接方法
如果给定的样本集是由各类都服从高斯分布的样本混合在一起组成的，在类别数已知的条件下，可以用最大似然法或Bayes估计法，从混合的概率密度函数中分解出各个类的概率密度函数，然后用Bayes决策方法设计模式分类器。在非高斯概率分布情况下，只要各类的概率密度函数的形式已知，且分解是惟一的，都可以用上述方法实现分类器设计。在没有任何概率分布先验知识的情况下，可以把特征空间划分为着若干个队域，使每个区域都具有单峰的分布性质，每一个区域就相当于一个类别，这样作的基础是紧致性假设。已经合多种算法实现这种队域的划分。
(2)基于样本间相似度呈的间接聚类方法
如果用样本在特征窄问中相互问的距离来度量样本间的相似度，就可以设计出某种评价分类质量的准则函数，通过数学方法把特征空间划分为与各个类别相对应的区域，也就是通常所说的聚类分析。算法和非迭代的分级聚类算法。前者是给定某个样本集的初始划分，计算反映聚类质量的准则隔数值，如果把某个样本从原来所属的类别改属为另一个类别能使准则函数值向好的方向改进，则改变这个样本原来的类别为新的类别(新的划分)再对其他样本进行类似的运算这样反复迭代，直到没有一个样本类别的改变能改进准则函数值，即已经达到了准则函数的最优值。这一类算法中著名的有C-均值算法和ISODATA算法，C-均值算法要求类别数预先给定，并把各样本到所属类别样本子集的均值向量的距离平方和作为评价聚类质量的准则函数。ISODATA算法可以自动地调整类别数，并可对各类样本的某些统计性质(如样本数餐、样本特征的标准偏差等)作些限制。非迭代的分级聚类算法：第一步把每一个样本都看成一个类，给定两类样本间相似度计算方法，计算类与类之间的相似度。第二步把其中相似度最大的两个类合并为一个类，再计算新的类与类之间的相似度。第三步再把其中相似把所有的样本都合为一类为止。根据问题的性质以及各级的相似度大小，就可以确定合理的聚类差别数和各类所包含的样本，在应用分级聚类算法时要选择适当的类与类间相似度汁算力’法，不同的计算方法会导致完全不同的聚类结果。
聚类分析是无监督学习的主要方法，它能从大量的数据集中找出有规律性的结果。为了适应各种实际问题的数据结构的特点，还发展了以上述方法为基础的各种其他算法
