表示学习，又称学习表示。在深度学习领域内，表示是指通过模型的参数，采用何种形式、何种方式来表示模型的输入观测样本X。表示学习指学习对观测样本X有效的表示。表示学习有很多种形式，比如CNN参数的有监督训练是一种有监督的表示学习形式，对自动编码器和限制玻尔兹曼机参数的无监督预训练是一种无监督的表示学习形式，对DBN参数-先进行无监督预训练，再进行有监督fine-tuning-是一种半监督的共享表示学习形式。

## 简介
表示学习是学习一个特征的技术的集合：将原始数据转换成为能够被机器学习来有效开发的一种形式。它避免了手动提取特征的麻烦，允许计算机学习使用特征的同时，也学习如何提取特征：学习如何学习。机器学习任务，例如分类问题，通常都要求输入在数学上或者在计算上都非常便于处理，在这样的前提下，特征学习就应运而生了。然而，在我们现实世界中的数据例如图片，视频，以及传感器的测量值都非常的复杂，冗余并且多变。那么，如何有效的提取出特征并且将其表达出来就显得非常重要。传统的手动提取特征需要大量的人力并且依赖于非常专业的知识。同时，还不便于推广。这就要求特征学习技术的整体设计非常有效，自动化，并且易于推广。表示学习中最关键的问题是：如何评价一个表示比另一个表示更好？表示的选择通常通常取决于随后的学习任务，即一个好的表示应该使随后的任务的学习变得更容易。
以无监督和有监督结合的共享表示学习为例。在深度学习任务中，我们通常有大量的无标签的训练样本和少量的有标签的训练样本。只在有限的有标签的训练样本上学习，会导致模型存在严重过拟合问题。共享表示具体来说，可以从大量无标签的观测样本中通过无监督的方法，学习出很好的表示，然后基于这些表示，采用少量有标签的观测样本来得到好的模型参数，缓解监督学习中的过拟合问题。
共享表示学习涉及多个任务，多个任务之间共享一定相同的因素，比如相同的分布（distribution）、观测样本X来自相同的领域（domain）等。共享表示学习有多种表示形式。假设共享表示学习中采用训练样本A进行无监督学习，训练样本B进行有监督学习。样本A和样本B可能来自相同的领域，也可能来自不同的领域；可能任务服从相同的分布，也可能服从不同的分布。

## 理论基础
表示学习得到的低维向量表示是一种分布式表示(distributed representation)。之所以如此命名，是因为孤立地看向量中的每一维，都没有明确对应的含义；而综合各维形成一个向量，则能够表示对象的语义信息。这种表示方案并非凭空而来，而是受到人脑的工作机制启发而来。我们知道，现实世界中的实体是离散的，不同对象之间有明显的界限。人脑通过大量神经元上的激活和抑制存储这些对象，形成内隐世界。显而易见，每个单独神经元的激活或抑制并没有明确含义，但是多个神经元的状态则能表示世间万物。受到该工作机制的启发，分布式表示的向量可以看作模拟人脑的多个神经元，每维对应一个神经元，而向量中的值对应神经元的激活或抑制状态。基于神经网络这种对离散世界的连续表示机制，人脑具备了高度的学习能力与智能水平。表示学习正是对人脑这一工作机制的模仿。还值得一提的是，现实世界存在层次结构一个对象往往由更小的对象组成。例如一个房屋作为一个对象，是由门、窗户、墙、天花板和地板等对象有机组合而成的，墙则由更小的砖块和水泥等对象组成，以此类推。这种层次或嵌套的结构反映在人脑中，形成了神经网络的层次结构。最近象征人工神经网络复兴的深度学习技术，其津津乐道的“深度”正是这种层次性的体现。

## 应用
知识表示学习是面向知识库中实体和关系的表示学习。通过将实体或关系投影到低维向量空间，我们能够实现对实体和关系的语义信息的表示，可以高效地计算实体、关系及其之间的复杂语义关联。这对知识库的构建、推理与应用均有重要意义。知识表示学习得到的分布式表示有以下典型应用：
1)相似度计算。利用实体的分布式表示，我们可以快速计算实体间的语义相似度，这对于自然语言处理和信息检索的很多任务具有重要意义。
2)知识图谱补全。构建大规模知识图谱，需要不断补充实体间的关系。利用知识表示学习模型，可以预测2个实体的关系，这一般称为知识库的链接预测，又称为知识图谱补全。
3)其他应用。知识表示学习已被广泛用于关系抽取、自动问答、实体链指等任务，展现出巨大的应用潜力。随着深度学习在自然语言处理各项重要任务中得到广泛应用，这将为知识表示学习带来更广阔的应用空间。

## 优点
知识表示学习实现了对实体和关系的分布式表示，它具有以下主要优点：
显著提升计算效率。知识库的三元组表示实际就是基于独热表示的。如前所分析的，在这种表示方式下，需要设计专门的图算法计算实体间的语义和推理关系，计算复杂度高、可扩展性差。而表示学习得到的分布式表示，则能够高效地实现语义相似度计算等操作，显著提升计算效率。
有效缓解数据稀疏。由于表示学习将对象投影到统一的低维空间中，使每个对象均对应一个稠密向量，从而有效缓解数据稀疏问题，这主要在2个方面体现。一方面，每个对象的向量均为稠密有值的，因此可以度量任意对象之间的语义相似程度。而基于独热表示的图算法，由于受到大规模知识图谱稀疏特性的影响，往往无法有效计算很多对象之间的语义相似度。另一方面，将大量对象投影到统一空间的过程，也能够将高频对象的语义信息用于帮助低频对象的语义表示，提高低频对象的语义表示的精确性。
实现异质信息融合。不同来源的异质信息需要融合为整体，才能得到有效应用。例如，人们构造了大量知识库，这些知识库的构建规范和信息来源均有不同，例如著名的世界知识库有DBPedia，YAGO，Freebase等。大量实体和关系在不同知识库中的名称不同。如何实现多知识库的有机融合，对知识库应用具有重要意义。如果基于网络表示，该任务只能通过设计专门图算法来实现，效果较差，效率低下。而通过设计合理的表示学习模型，将不同来源的对象投影到同一个语义空间中，就能够建立统一的表示空间，实现多知识库的信息融合。此外，当我们在信息检索或自然语言处理中应用知识库时，往往需要计算查询词、句子、文档和知识库实体之间的复杂语义关联。由于这些对象的异质性，计算它们的语义关联往往是棘手问题。而表示学习亦能为异质对象提供统一表示空问，轻而易举实现异质对象之间的语义关联计算。
